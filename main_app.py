import streamlit as st
import pandas as pd
import networkx as nx
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import seaborn as sns
import numpy as np
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

# Importar mÃ³dulos locales
from data_loader import load_and_process_data
from network_analyzer import NetworkAnalyzer
from visualizer import NetworkVisualizer
from community_detector import AIOptimizedCommunityDetector
from ai_optimizer import AINetworkOptimizer

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(
    page_title="AnÃ¡lisis de Redes Sociales con IA - GitHub",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personalizado
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .section-header {
        font-size: 1.8rem;
        color: #2E86AB;
        margin-top: 2rem;
        margin-bottom: 1rem;
    }
    .ai-highlight {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 0.5rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 0.25rem solid #1f77b4;
    }
    .stDataFrame {
        background-color: white;
    }
    .optimization-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 1.5rem;
        border-radius: 1rem;
        margin: 1rem 0;
    }
    .comparison-section {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border: 1px solid #dee2e6;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def main():
    # TÃ­tulo principal con Ã©nfasis en IA
    st.markdown('<h1 class="main-header">ğŸ¤– AnÃ¡lisis de Redes Sociales con IA en GitHub</h1>', unsafe_allow_html=True)
    
    st.markdown('<div class="ai-highlight">âœ¨ Potenciado por Algoritmos de Inteligencia Artificial para OptimizaciÃ³n de Colaboraciones</div>', unsafe_allow_html=True)
    
    # Sidebar
    with st.sidebar:
        st.image("https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png", width=100)
        st.title("ğŸ¤– Panel de Control IA")
        st.markdown("---")
        
        # Selector de secciÃ³n
        section = st.selectbox(
            "Selecciona una secciÃ³n:",
            [
                "ğŸ“ˆ Resumen General", 
                "ğŸ” AnÃ¡lisis de Red Base", 
                "ğŸ‘¥ Comunidades IA", 
                "ğŸ† LÃ­deres TÃ©cnicos",
                "ğŸ¤– OptimizaciÃ³n IA Completa",
                "ğŸ“Š Patrones Colaborativos",
                "ğŸ“‹ Recomendaciones IA",
                "ğŸ”¬ AnÃ¡lisis Comparativo Antes/DespuÃ©s"
            ]
        )
        
        st.markdown("---")
        
        # Configuraciones de IA
        st.markdown("### âš™ï¸ ConfiguraciÃ³n IA")
        
        community_method = st.selectbox(
            "MÃ©todo de DetecciÃ³n de Comunidades:",
            ['hybrid_ai', 'spectral_ai', 'kmeans_ai', 'greedy', 'louvain']
        )
        
        optimization_level = st.slider(
            "Nivel de OptimizaciÃ³n IA:",
            min_value=1, max_value=5, value=3,
            help="1=BÃ¡sico, 5=MÃ¡ximo (mÃ¡s lento)"
        )
        
        st.markdown("---")
        st.markdown("### â„¹ï¸ InformaciÃ³n")
        st.info("Este dashboard utiliza algoritmos avanzados de IA para analizar y optimizar colaboraciones en GitHub.")
    
    # Cargar datos
    try:
        with st.spinner("ğŸ”„ Cargando y procesando datos..."):
            df = load_and_process_data()
            G = create_network_graph(df)
            
            # Inicializar componentes con IA
            analyzer = NetworkAnalyzer(G)
            visualizer = NetworkVisualizer(G)
            ai_community_detector = AIOptimizedCommunityDetector(G)
            ai_optimizer = AINetworkOptimizer(G, df)
            
            # Calcular mÃ©tricas bÃ¡sicas
            metrics = analyzer.calculate_all_metrics()
        
        st.success("âœ… Datos cargados y analizados exitosamente")
        
    except Exception as e:
        st.error(f"âŒ Error al cargar los datos: {str(e)}")
        st.info("ğŸ’¡ AsegÃºrate de tener instaladas todas las dependencias: `pip install scikit-learn`")
        st.stop()
    
    # Mostrar secciÃ³n seleccionada
    if section == "ğŸ“ˆ Resumen General":
        show_general_overview(df, G, metrics)
    elif section == "ğŸ” AnÃ¡lisis de Red Base":
        show_base_network_analysis(G, metrics, visualizer, df)
    elif section == "ğŸ‘¥ Comunidades IA":
        show_ai_community_analysis(G, ai_community_detector, df, community_method)
    elif section == "ğŸ† LÃ­deres TÃ©cnicos":
        show_technical_leaders_classification(metrics, G, df, ai_optimizer)
    elif section == "ğŸ¤– OptimizaciÃ³n IA Completa":
        show_complete_ai_optimization(ai_optimizer, G, df, visualizer)
    elif section == "ğŸ“Š Patrones Colaborativos":
        show_collaboration_patterns(ai_optimizer)
    elif section == "ğŸ“‹ Recomendaciones IA":
        show_ai_recommendations(G, metrics, ai_optimizer, df)
    elif section == "ğŸ”¬ AnÃ¡lisis Comparativo Antes/DespuÃ©s":
        show_before_after_analysis(G, df, ai_optimizer, visualizer)

def create_network_graph(df):
    """Crear grafo de NetworkX desde el DataFrame"""
    G = nx.DiGraph()
    
    # Agregar nodos
    developers = set(df['developer_source'].unique()) | set(df['developer_target'].unique())
    G.add_nodes_from(developers)
    
    # Agregar aristas con pesos
    for _, row in df.iterrows():
        source = row['developer_source']
        target = row['developer_target']
        weight = row['weight']
        
        if G.has_edge(source, target):
            G[source][target]['weight'] += weight
        else:
            G.add_edge(source, target, weight=weight)
    
    return G

def calculate_detailed_metrics(G):
    """Calcula mÃ©tricas detalladas del grafo"""
    metrics = {}
    
    # MÃ©tricas bÃ¡sicas
    metrics['num_nodes'] = G.number_of_nodes()
    metrics['num_edges'] = G.number_of_edges()
    metrics['density'] = nx.density(G)
    
    # MÃ©tricas de centralidad
    metrics['pagerank'] = nx.pagerank(G, weight='weight')
    metrics['betweenness_centrality'] = nx.betweenness_centrality(G, weight='weight')
    metrics['degree_centrality'] = nx.degree_centrality(G)
    metrics['closeness_centrality'] = nx.closeness_centrality(G, distance='weight')
    
    try:
        metrics['eigenvector_centrality'] = nx.eigenvector_centrality(G, weight='weight', max_iter=1000)
    except:
        metrics['eigenvector_centrality'] = nx.eigenvector_centrality(G, max_iter=1000)
    
    # MÃ©tricas globales
    undirected_G = G.to_undirected()
    metrics['avg_clustering'] = nx.average_clustering(undirected_G, weight='weight')
    metrics['num_components'] = nx.number_connected_components(undirected_G)
    metrics['reciprocity'] = nx.reciprocity(G)
    
    if nx.is_connected(undirected_G):
        metrics['diameter'] = nx.diameter(undirected_G)
        metrics['avg_path_length'] = nx.average_shortest_path_length(undirected_G)
    else:
        metrics['diameter'] = float('inf')
        metrics['avg_path_length'] = float('inf')
    
    return metrics

def show_base_network_analysis(G, metrics, visualizer, df):
    """AnÃ¡lisis de la Red de ColaboraciÃ³n Base segÃºn el taller"""
    st.markdown('<h2 class="section-header">ğŸ” AnÃ¡lisis de la Red de ColaboraciÃ³n Base</h2>', unsafe_allow_html=True)
    
    # MÃ©tricas estructurales de la red base (Tabla del taller)
    st.subheader("ğŸ“Š MÃ©tricas Estructurales de la Red Base")
    
    # Calcular mÃ©tricas especÃ­ficas como en el taller
    undirected_G = G.to_undirected()
    
    base_metrics = {
        'Densidad de red': nx.density(G),
        'Clustering promedio': nx.average_clustering(undirected_G, weight='weight'),
        'Componentes conectados': nx.number_connected_components(undirected_G),
        'DiÃ¡metro de red': nx.diameter(undirected_G) if nx.is_connected(undirected_G) else float('inf'),
        'Reciprocidad': nx.reciprocity(G)
    }
    
    # Crear tabla como en el taller
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("ğŸ“Š Densidad de red", f"{base_metrics['Densidad de red']:.3f}")
        st.write("*Red moderadamente conectada*")
    
    with col2:
        st.metric("ğŸ•¸ï¸ Clustering promedio", f"{base_metrics['Clustering promedio']:.3f}")
        st.write("*Alta tendencia a formaciÃ³n de grupos*")
    
    with col3:
        st.metric("ğŸ”— Componentes conectados", base_metrics['Componentes conectados'])
        st.write("*Red completamente conectada*")
    
    col1, col2 = st.columns(2)
    
    with col1:
        diameter_val = base_metrics['DiÃ¡metro de red']
        if diameter_val != float('inf'):
            st.metric("ğŸ“ DiÃ¡metro de red", diameter_val)
            st.write("*ComunicaciÃ³n eficiente*")
        else:
            st.metric("ğŸ“ DiÃ¡metro de red", "âˆ")
            st.write("*Red desconectada*")
    
    with col2:
        st.metric("ğŸ”„ Reciprocidad", f"{base_metrics['Reciprocidad']:.3f}")
        st.write("*Alta colaboraciÃ³n bidireccional*")
    
    # Tabla de mÃ©tricas estructurales como en el documento
    st.subheader("ğŸ“‹ Cuadro 1: MÃ©tricas estructurales de la red base")
    
    metrics_df = pd.DataFrame([
        {'MÃ©trica': 'Densidad de red', 'Valor Inicial': f"{base_metrics['Densidad de red']:.3f}", 'InterpretaciÃ³n': 'Red moderadamente conectada'},
        {'MÃ©trica': 'Clustering promedio', 'Valor Inicial': f"{base_metrics['Clustering promedio']:.3f}", 'InterpretaciÃ³n': 'Alta tendencia a formaciÃ³n de grupos'},
        {'MÃ©trica': 'Componentes conectados', 'Valor Inicial': base_metrics['Componentes conectados'], 'InterpretaciÃ³n': 'Red completamente conectada'},
        {'MÃ©trica': 'DiÃ¡metro de red', 'Valor Inicial': base_metrics['DiÃ¡metro de red'] if base_metrics['DiÃ¡metro de red'] != float('inf') else 'âˆ', 'InterpretaciÃ³n': 'ComunicaciÃ³n eficiente'},
        {'MÃ©trica': 'Reciprocidad', 'Valor Inicial': f"{base_metrics['Reciprocidad']:.3f}", 'InterpretaciÃ³n': 'Alta colaboraciÃ³n bidireccional'}
    ])
    
    st.dataframe(metrics_df, use_container_width=True)
    
    # InformaciÃ³n del dataset como en el taller
    st.subheader("ğŸ“ˆ InformaciÃ³n del Dataset")
    
    developers = set(df['developer_source'].unique()) | set(df['developer_target'].unique())
    repos = df['repo'].unique()
    interactions = len(df)
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ğŸ‘¥ Desarrolladores", len(developers))
    
    with col2:
        st.metric("ğŸ“ Repositorios principales", len(repos))
    
    with col3:
        st.metric("ğŸ”„ Interacciones documentadas", interactions)
    
    with col4:
        # Calcular perÃ­odo (aproximado)
        if 'timestamp' in df.columns and not df['timestamp'].isna().all():
            date_range = pd.to_datetime(df['timestamp']).max() - pd.to_datetime(df['timestamp']).min()
            period = f"{date_range.days} dÃ­as"
        else:
            period = "3 meses (estimado)"
        st.metric("ğŸ“… PerÃ­odo", period)
    
    # VisualizaciÃ³n de la red base
    st.subheader("ğŸ•¸ï¸ VisualizaciÃ³n de la Red Base")
    
    col1, col2 = st.columns([3, 1])
    
    with col2:
        metric_option = st.selectbox(
            "MÃ©trica para colorear:",
            ['pagerank', 'betweenness', 'closeness', 'eigenvector'],
            key="base_metric"
        )
    
    with col1:
        fig = visualizer.create_network_plot(metrics, metric_option, 
                                           title="Red de ColaboraciÃ³n Base - GitHub")
        st.plotly_chart(fig, use_container_width=True)
    
    # AnÃ¡lisis detallado por repositorio
    st.subheader("ğŸ“ AnÃ¡lisis por Repositorio")
    
    repo_analysis = []
    for repo in repos:
        repo_data = df[df['repo'] == repo]
        repo_devs = set(repo_data['developer_source']) | set(repo_data['developer_target'])
        
        repo_analysis.append({
            'Repositorio': repo,
            'Interacciones': len(repo_data),
            'Desarrolladores': len(repo_devs),
            'Peso Promedio': repo_data['weight'].mean(),
            'Tipos de InteracciÃ³n': len(repo_data['interaction_type'].unique())
        })
    
    repo_df = pd.DataFrame(repo_analysis)
    st.dataframe(repo_df.style.format({
        'Peso Promedio': '{:.2f}'
    }).background_gradient(subset=['Interacciones']), use_container_width=True)

def show_technical_leaders_classification(metrics, G, df, ai_optimizer):
    """Sistema de ClasificaciÃ³n Inteligente de Desarrolladores como en el taller"""
    st.markdown('<h2 class="section-header">ğŸ† Sistema de ClasificaciÃ³n Inteligente de Desarrolladores</h2>', unsafe_allow_html=True)
    
    st.markdown('<div class="ai-highlight">ğŸ¤– Algoritmo de scoring multidimensional para clasificaciÃ³n automÃ¡tica</div>', unsafe_allow_html=True)
    
    # Calcular scoring multidimensional como en el taller
    developers = list(G.nodes())
    
    # Pesos para el scoring (como en el taller)
    weights = {
        'pagerank': 0.35,
        'betweenness': 0.30,
        'eigenvector': 0.20,
        'closeness': 0.15
    }
    
    # Calcular scores IA
    ai_scores = {}
    for dev in developers:
        score = 0
        score += metrics['pagerank'][dev] * weights['pagerank'] * 10  # Normalizar
        score += metrics['betweenness'][dev] * weights['betweenness'] * 10
        score += metrics['eigenvector'][dev] * weights['eigenvector'] * 10
        score += metrics['closeness'][dev] * weights['closeness'] * 10
        ai_scores[dev] = score
    
    # Clasificar en roles (como en el taller)
    sorted_devs = sorted(ai_scores.items(), key=lambda x: x[1], reverse=True)
    
    # Determinar especializaciÃ³n basada en datos
    specializations = {}
    for dev in developers:
        dev_data = df[(df['developer_source'] == dev) | (df['developer_target'] == dev)]
        if len(dev_data) > 0:
            # Determinar especializaciÃ³n por repositorio mÃ¡s frecuente
            top_repo = dev_data['repo'].value_counts().index[0] if len(dev_data) > 0 else 'general'
            if 'frontend' in top_repo.lower():
                specializations[dev] = 'Frontend/Interfaces'
            elif 'backend' in top_repo.lower() or 'api' in top_repo.lower():
                specializations[dev] = 'Backend/Servicios'
            elif 'data' in top_repo.lower():
                specializations[dev] = 'Datos/Analytics'
            else:
                specializations[dev] = 'Desarrollo General'
        else:
            specializations[dev] = 'Sin especializaciÃ³n'
    
    # Asignar roles basado en percentiles (como en el taller)
    scores = list(ai_scores.values())
    threshold_leader = np.percentile(scores, 80)
    threshold_connector = np.percentile(scores, 60)
    threshold_senior = np.percentile(scores, 40)
    
    classified_devs = []
    for dev, score in sorted_devs:
        if score >= threshold_leader and metrics['betweenness'][dev] > np.percentile(list(metrics['betweenness'].values()), 70):
            role = 'LÃ­der TÃ©cnico'
        elif metrics['betweenness'][dev] > np.percentile(list(metrics['betweenness'].values()), 80):
            role = 'Conector Principal'
        elif score >= threshold_senior:
            role = 'Colaborador Senior'
        elif 'backend' in specializations[dev].lower() or 'data' in specializations[dev].lower():
            role = 'Especialista Backend'
        elif 'frontend' in specializations[dev].lower():
            role = 'Desarrollador Frontend'
        else:
            role = 'Desarrollador Junior'
        
        classified_devs.append({
            'Desarrollador': dev,
            'Rol Identificado': role,
            'Score IA': f"{score:.3f}",
            'EspecializaciÃ³n': specializations[dev],
            'PageRank': f"{metrics['pagerank'][dev]:.3f}",
            'IntermediaciÃ³n': f"{metrics['betweenness'][dev]:.3f}",
            'Colaboraciones': len(df[(df['developer_source'] == dev) | (df['developer_target'] == dev)])
        })
    
    # Mostrar tabla de clasificaciÃ³n como en el taller (Cuadro 2)
    st.subheader("ğŸ“‹ Cuadro 2: ClasificaciÃ³n automÃ¡tica de roles por IA")
    
    classification_df = pd.DataFrame(classified_devs)
    
    st.dataframe(
        classification_df.style.background_gradient(subset=['Score IA']),
        use_container_width=True
    )
    
    # AnÃ¡lisis de distribuciÃ³n de roles
    st.subheader("ğŸ“Š DistribuciÃ³n de Roles Identificados")
    
    role_counts = classification_df['Rol Identificado'].value_counts()
    
    col1, col2 = st.columns(2)
    
    with col1:
        fig = px.pie(values=role_counts.values, names=role_counts.index,
                    title="DistribuciÃ³n de Roles por IA")
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        fig = px.bar(x=role_counts.index, y=role_counts.values,
                    title="Cantidad por Rol")
        fig.update_layout(xaxis_tickangle=45)
        st.plotly_chart(fig, use_container_width=True)
    
    # Radar chart para top 5 desarrolladores
    st.subheader("ğŸ“¡ Perfil Multidimensional - Top 5 Desarrolladores")
    
    top_5 = classified_devs[:5]
    
    categories = ['PageRank', 'IntermediaciÃ³n', 'Eigenvector', 'CercanÃ­a', 'Colaboraciones']
    
    fig = go.Figure()
    
    colors = ['red', 'blue', 'green', 'orange', 'purple']
    
    for i, dev_data in enumerate(top_5):
        dev = dev_data['Desarrollador']
        collab_count = dev_data['Colaboraciones']
        max_collabs = max([d['Colaboraciones'] for d in classified_devs])
        
        values = [
            metrics['pagerank'][dev] / max(metrics['pagerank'].values()),
            metrics['betweenness'][dev] / max(metrics['betweenness'].values()) if max(metrics['betweenness'].values()) > 0 else 0,
            metrics['eigenvector'][dev] / max(metrics['eigenvector'].values()) if max(metrics['eigenvector'].values()) > 0 else 0,
            metrics['closeness'][dev] / max(metrics['closeness'].values()),
            collab_count / max_collabs
        ]
        values += values[:1]  # Cerrar el polÃ­gono
        
        fig.add_trace(go.Scatterpolar(
            r=values,
            theta=categories + [categories[0]],
            fill='toself',
            name=dev,
            line_color=colors[i],
            fillcolor=colors[i],
            opacity=0.6
        ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(visible=True, range=[0, 1])
        ),
        title="AnÃ¡lisis Multidimensional de LÃ­deres TÃ©cnicos",
        showlegend=True
    )
    
    st.plotly_chart(fig, use_container_width=True)

def show_complete_ai_optimization(ai_optimizer, G, df, visualizer):
    """OptimizaciÃ³n completa con mÃ©tricas antes/despuÃ©s"""
    st.markdown('<h2 class="section-header">ğŸ¤– OptimizaciÃ³n Completa con IA</h2>', unsafe_allow_html=True)
    
    st.markdown('<div class="optimization-card">ğŸš€ AnÃ¡lisis completo: Antes â†’ Algoritmo de OptimizaciÃ³n â†’ DespuÃ©s</div>', unsafe_allow_html=True)
    
    # MÃ©tricas antes de la optimizaciÃ³n
    st.subheader("ğŸ“Š Estado Actual (Antes de OptimizaciÃ³n)")
    
    original_metrics = calculate_detailed_metrics(G)
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("ğŸ˜ï¸ Nodos", original_metrics['num_nodes'])
    with col2:
        st.metric("ğŸ”— Aristas", original_metrics['num_edges'])
    with col3:
        st.metric("ğŸ“Š Densidad", f"{original_metrics['density']:.3f}")
    with col4:
        st.metric("ğŸ•¸ï¸ Clustering", f"{original_metrics['avg_clustering']:.3f}")
    with col5:
        st.metric("ğŸ”„ Reciprocidad", f"{original_metrics['reciprocity']:.3f}")
    
    # Top nodos por centralidad de intermediaciÃ³n (antes)
    st.subheader("ğŸŒ‰ Top Nodos - Centralidad de IntermediaciÃ³n (ANTES)")
    
    betweenness_before = sorted(original_metrics['betweenness_centrality'].items(), 
                               key=lambda x: x[1], reverse=True)[:10]
    
    bet_df_before = pd.DataFrame(betweenness_before, columns=['Desarrollador', 'IntermediaciÃ³n'])
    bet_df_before['Rango'] = range(1, len(bet_df_before) + 1)
    
    fig_bet_before = px.bar(bet_df_before, x='IntermediaciÃ³n', y='Desarrollador',
                           orientation='h', title="Centralidad de IntermediaciÃ³n - ANTES",
                           color='IntermediaciÃ³n', color_continuous_scale='viridis')
    st.plotly_chart(fig_bet_before, use_container_width=True)
    
    # Top nodos por centralidad de grado (antes)
    st.subheader("ğŸ“Š Top Nodos - Centralidad de Grado (ANTES)")
    
    degree_before = sorted(original_metrics['degree_centrality'].items(), 
                          key=lambda x: x[1], reverse=True)[:10]
    
    deg_df_before = pd.DataFrame(degree_before, columns=['Desarrollador', 'Grado'])
    deg_df_before['Rango'] = range(1, len(deg_df_before) + 1)
    
    fig_deg_before = px.bar(deg_df_before, x='Grado', y='Desarrollador',
                           orientation='h', title="Centralidad de Grado - ANTES",
                           color='Grado', color_continuous_scale='plasma')
    st.plotly_chart(fig_deg_before, use_container_width=True)
    
    # Ejecutar optimizaciÃ³n
    st.subheader("ğŸš€ Ejecutar OptimizaciÃ³n IA")
    
    if st.button("ğŸ¤– Ejecutar OptimizaciÃ³n Completa del Grafo", type="primary"):
        with st.spinner("ğŸ”„ Ejecutando algoritmos de optimizaciÃ³n..."):
            
            # Aplicar optimizaciÃ³n usando el optimizador mejorado
            G_optimized = ai_optimizer.apply_optimization_recommendations(top_recommendations=5)
            
            # Obtener comparaciÃ³n completa
            comparison_results = ai_optimizer.get_optimization_comparison()
            
            # Guardar en session state para mantener resultados
            st.session_state['original_metrics'] = original_metrics
            st.session_state['optimized_metrics'] = ai_optimizer.optimized_metrics
            st.session_state['G_optimized'] = G_optimized
            st.session_state['optimization_applied'] = True
            st.session_state['comparison_results'] = comparison_results
        
        st.success("âœ… OptimizaciÃ³n completada!")
        st.rerun()
    
    # Mostrar resultados si ya se ejecutÃ³ la optimizaciÃ³n
    if st.session_state.get('optimization_applied', False):
        
        optimized_metrics = st.session_state['optimized_metrics']
        G_optimized = st.session_state['G_optimized']
        comparison_results = st.session_state.get('comparison_results', {})
        
        st.subheader("ğŸ“ˆ Estado DespuÃ©s de OptimizaciÃ³n")
        
        col1, col2, col3, col4, col5 = st.columns(5)
        
        with col1:
            delta_nodes = optimized_metrics['num_nodes'] - original_metrics['num_nodes']
            st.metric("ğŸ˜ï¸ Nodos", optimized_metrics['num_nodes'], delta=delta_nodes)
        with col2:
            delta_edges = optimized_metrics['num_edges'] - original_metrics['num_edges']
            st.metric("ğŸ”— Aristas", optimized_metrics['num_edges'], delta=delta_edges)
        with col3:
            delta_density = optimized_metrics['density'] - original_metrics['density']
            st.metric("ğŸ“Š Densidad", f"{optimized_metrics['density']:.3f}", 
                     delta=f"{delta_density:+.3f}")
        with col4:
            delta_clustering = optimized_metrics['avg_clustering'] - original_metrics['avg_clustering']
            st.metric("ğŸ•¸ï¸ Clustering", f"{optimized_metrics['avg_clustering']:.3f}", 
                     delta=f"{delta_clustering:+.3f}")
        with col5:
            delta_reciprocity = optimized_metrics['reciprocity'] - original_metrics['reciprocity']
            st.metric("ğŸ”„ Reciprocidad", f"{optimized_metrics['reciprocity']:.3f}", 
                     delta=f"{delta_reciprocity:+.3f}")
        
        # Grafo despuÃ©s de la optimizaciÃ³n
        st.subheader("ğŸ•¸ï¸ Grafo DespuÃ©s de Aplicar el Algoritmo de OptimizaciÃ³n")
        
        # Crear visualizador para el grafo optimizado
        visualizer_optimized = NetworkVisualizer(G_optimized)
        metrics_optimized = {
            'pagerank': optimized_metrics['pagerank'],
            'betweenness': optimized_metrics['betweenness_centrality'],
            'closeness': optimized_metrics['closeness_centrality'],
            'eigenvector': optimized_metrics['eigenvector_centrality']
        }
        
        col1, col2 = st.columns([3, 1])
        
        with col2:
            metric_option_opt = st.selectbox(
                "MÃ©trica para colorear (optimizado):",
                ['pagerank', 'betweenness', 'closeness', 'eigenvector'],
                key="optimized_metric"
            )
        
        with col1:
            fig_optimized = visualizer_optimized.create_network_plot(
                metrics_optimized, metric_option_opt, 
                title="Grafo OPTIMIZADO - Red de ColaboraciÃ³n"
            )
            st.plotly_chart(fig_optimized, use_container_width=True)
        
        # Top nodos por centralidad de intermediaciÃ³n (despuÃ©s)
        st.subheader("ğŸŒ‰ Top Nodos - Centralidad de IntermediaciÃ³n (DESPUÃ‰S)")
        
        betweenness_after = sorted(optimized_metrics['betweenness_centrality'].items(), 
                                  key=lambda x: x[1], reverse=True)[:10]
        
        bet_df_after = pd.DataFrame(betweenness_after, columns=['Desarrollador', 'IntermediaciÃ³n'])
        bet_df_after['Rango'] = range(1, len(bet_df_after) + 1)
        
        fig_bet_after = px.bar(bet_df_after, x='IntermediaciÃ³n', y='Desarrollador',
                              orientation='h', title="Centralidad de IntermediaciÃ³n - DESPUÃ‰S",
                              color='IntermediaciÃ³n', color_continuous_scale='viridis')
        st.plotly_chart(fig_bet_after, use_container_width=True)
        
        # Top nodos por centralidad de grado (despuÃ©s)
        st.subheader("ğŸ“Š Top Nodos - Centralidad de Grado (DESPUÃ‰S)")
        
        degree_after = sorted(optimized_metrics['degree_centrality'].items(), 
                             key=lambda x: x[1], reverse=True)[:10]
        
        deg_df_after = pd.DataFrame(degree_after, columns=['Desarrollador', 'Grado'])
        deg_df_after['Rango'] = range(1, len(deg_df_after) + 1)
        
        fig_deg_after = px.bar(deg_df_after, x='Grado', y='Desarrollador',
                              orientation='h', title="Centralidad de Grado - DESPUÃ‰S",
                              color='Grado', color_continuous_scale='plasma')
        st.plotly_chart(fig_deg_after, use_container_width=True)
        
        # Resumen de mejoras conseguidas
        if comparison_results.get('improvement_summary'):
            improvement_summary = comparison_results['improvement_summary']
            
            st.subheader("ğŸ¯ Resumen de Mejoras Conseguidas")
            
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric(
                    "ğŸ“ˆ MÃ©tricas Mejoradas",
                    f"{improvement_summary['metrics_improved']}/{improvement_summary['total_metrics']}",
                    help="NÃºmero de mÃ©tricas que mejoraron"
                )
            
            with col2:
                st.metric(
                    "ğŸ”— Nuevas Conexiones",
                    improvement_summary['new_connections'],
                    help="Conexiones completamente nuevas aÃ±adidas"
                )
            
            with col3:
                st.metric(
                    "ğŸ’ª Conexiones Reforzadas",
                    improvement_summary['reinforced_connections'],
                    help="Conexiones existentes que se reforzaron"
                )
            
            with col4:
                st.metric(
                    "ğŸš§ Cuellos de Botella Mitigados",
                    improvement_summary['bottlenecks_mitigated'],
                    help="Cuellos de botella crÃ­ticos que se aliviaron"
                )
        
        # Tabla comparativa detallada de mÃ©tricas globales
        st.subheader("ğŸ“‹ ComparaciÃ³n Detallada: MÃ©tricas Globales")
        
        if comparison_results.get('metrics_comparison'):
            comparison_data = []
            
            for metric_name, metric_data in comparison_results['metrics_comparison'].items():
                comparison_data.append({
                    'MÃ©trica': metric_name.replace('_', ' ').title(),
                    'Antes': f"{metric_data['before']:.4f}" if isinstance(metric_data['before'], float) else str(metric_data['before']),
                    'DespuÃ©s': f"{metric_data['after']:.4f}" if isinstance(metric_data['after'], float) else str(metric_data['after']),
                    'Cambio': f"{metric_data['change']:+.4f}" if isinstance(metric_data['change'], float) else f"{metric_data['change']:+d}",
                    'Cambio %': f"{metric_data['change_percentage']:+.2f}%" if metric_data['change_percentage'] != 0 else "0.00%",
                    'MejorÃ³': "âœ…" if metric_data.get('improved', False) else "â–"
                })
            
            comparison_df = pd.DataFrame(comparison_data)
            
            st.dataframe(
                comparison_df.style.applymap(
                    lambda x: 'background-color: lightgreen' if 'âœ…' in str(x) else 
                             'background-color: lightcoral' if 'â–' in str(x) else '',
                    subset=['MejorÃ³']
                ).applymap(
                    lambda x: 'background-color: lightgreen' if '+' in str(x) and '%' in str(x) and x != '+0.00%' else 
                             'background-color: lightcoral' if '-' in str(x) and '%' in str(x) else '',
                    subset=['Cambio %']
                ),
                use_container_width=True
            )

def show_before_after_analysis(G, df, ai_optimizer, visualizer):
    """AnÃ¡lisis detallado antes/despuÃ©s de optimizaciÃ³n"""
    st.markdown('<h2 class="section-header">ğŸ”¬ AnÃ¡lisis Comparativo Detallado: Antes/DespuÃ©s</h2>', unsafe_allow_html=True)
    
    if not st.session_state.get('optimization_applied', False):
        st.info("ğŸ’¡ Para ver la comparaciÃ³n detallada, primero ejecuta la optimizaciÃ³n en la secciÃ³n 'ğŸ¤– OptimizaciÃ³n IA Completa'")
        
        # NUEVA SECCIÃ“N: Mostrar mÃ©tricas actuales mientras tanto
        st.subheader("ğŸ“Š MÃ©tricas Actuales de la Red")
        current_metrics = calculate_detailed_metrics(G)
        
        col1, col2, col3, col4, col5 = st.columns(5)
        with col1:
            st.metric("ğŸ˜ï¸ Nodos", current_metrics['num_nodes'])
        with col2:
            st.metric("ğŸ”— Aristas", current_metrics['num_edges'])
        with col3:
            st.metric("ğŸ“Š Densidad", f"{current_metrics['density']:.3f}")
        with col4:
            st.metric("ğŸ•¸ï¸ Clustering", f"{current_metrics['avg_clustering']:.3f}")
        with col5:
            st.metric("ğŸ”„ Reciprocidad", f"{current_metrics['reciprocity']:.3f}")
        
        # Mostrar tabla de centralidad actual
        st.subheader("ğŸ† Rankings Actuales de Centralidad")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Top 10 - PageRank:**")
            pagerank_current = sorted(current_metrics['pagerank'].items(), key=lambda x: x[1], reverse=True)[:10]
            pagerank_df = pd.DataFrame(pagerank_current, columns=['Desarrollador', 'PageRank'])
            pagerank_df['Rango'] = range(1, len(pagerank_df) + 1)
            st.dataframe(pagerank_df[['Rango', 'Desarrollador', 'PageRank']], use_container_width=True)
        
        with col2:
            st.write("**Top 10 - IntermediaciÃ³n:**")
            betweenness_current = sorted(current_metrics['betweenness_centrality'].items(), key=lambda x: x[1], reverse=True)[:10]
            betweenness_df = pd.DataFrame(betweenness_current, columns=['Desarrollador', 'IntermediaciÃ³n'])
            betweenness_df['Rango'] = range(1, len(betweenness_df) + 1)
            st.dataframe(betweenness_df[['Rango', 'Desarrollador', 'IntermediaciÃ³n']], use_container_width=True)
        
        return
    
    original_metrics = st.session_state['original_metrics']
    optimized_metrics = st.session_state['optimized_metrics']
    G_optimized = st.session_state['G_optimized']
    
    # ComparaciÃ³n visual lado a lado
    st.subheader("ğŸ‘ï¸ ComparaciÃ³n Visual: Grafos Antes vs DespuÃ©s")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("#### ğŸ“Š ANTES de la OptimizaciÃ³n")
        
        metrics_before = {
            'pagerank': original_metrics['pagerank'],
            'betweenness': original_metrics['betweenness_centrality'],
            'closeness': original_metrics['closeness_centrality'],
            'eigenvector': original_metrics['eigenvector_centrality']
        }
        
        fig_before = visualizer.create_network_plot(
            metrics_before, 'pagerank', 
            title="Red Original"
        )
        st.plotly_chart(fig_before, use_container_width=True)
        
        # MÃ©tricas clave antes
        st.write("**MÃ©tricas Clave:**")
        st.write(f"â€¢ Densidad: {original_metrics['density']:.3f}")
        st.write(f"â€¢ Clustering: {original_metrics['avg_clustering']:.3f}")
        st.write(f"â€¢ Aristas: {original_metrics['num_edges']}")
        st.write(f"â€¢ Reciprocidad: {original_metrics['reciprocity']:.3f}")
    
    with col2:
        st.markdown("#### ğŸš€ DESPUÃ‰S de la OptimizaciÃ³n")
        
        visualizer_optimized = NetworkVisualizer(G_optimized)
        metrics_after = {
            'pagerank': optimized_metrics['pagerank'],
            'betweenness': optimized_metrics['betweenness_centrality'],
            'closeness': optimized_metrics['closeness_centrality'],
            'eigenvector': optimized_metrics['eigenvector_centrality']
        }
        
        fig_after = visualizer_optimized.create_network_plot(
            metrics_after, 'pagerank', 
            title="Red Optimizada"
        )
        st.plotly_chart(fig_after, use_container_width=True)
        
        # MÃ©tricas clave despuÃ©s
        st.write("**MÃ©tricas Clave:**")
        st.write(f"â€¢ Densidad: {optimized_metrics['density']:.3f}")
        st.write(f"â€¢ Clustering: {optimized_metrics['avg_clustering']:.3f}")
        st.write(f"â€¢ Aristas: {optimized_metrics['num_edges']}")
        st.write(f"â€¢ Reciprocidad: {optimized_metrics['reciprocity']:.3f}")
    
    # AnÃ¡lisis de cambios en ranking
    st.subheader("ğŸ“ˆ Cambios en Rankings de Centralidad")
    
    # Betweenness centrality changes
    betweenness_before_rank = {dev: rank for rank, (dev, _) in enumerate(
        sorted(original_metrics['betweenness_centrality'].items(), key=lambda x: x[1], reverse=True), 1)}
    betweenness_after_rank = {dev: rank for rank, (dev, _) in enumerate(
        sorted(optimized_metrics['betweenness_centrality'].items(), key=lambda x: x[1], reverse=True), 1)}
    
    ranking_changes = []
    for dev in G.nodes():
        before_rank = betweenness_before_rank.get(dev, len(G.nodes()))
        after_rank = betweenness_after_rank.get(dev, len(G.nodes()))
        change = before_rank - after_rank  # Positivo = mejora en ranking
        
        ranking_changes.append({
            'Desarrollador': dev,
            'Ranking Antes': before_rank,
            'Ranking DespuÃ©s': after_rank,
            'Cambio': change,
            'Centralidad Antes': f"{original_metrics['betweenness_centrality'][dev]:.3f}",
            'Centralidad DespuÃ©s': f"{optimized_metrics['betweenness_centrality'][dev]:.3f}"
        })
    
    ranking_df = pd.DataFrame(ranking_changes)
    ranking_df = ranking_df.sort_values('Cambio', ascending=False)
    
    st.subheader("ğŸ”„ Cambios en Ranking de Centralidad de IntermediaciÃ³n")
    st.dataframe(
        ranking_df.style.applymap(
            lambda x: 'background-color: lightgreen' if isinstance(x, (int, float)) and x > 0 else 
                     'background-color: lightcoral' if isinstance(x, (int, float)) and x < 0 else '',
            subset=['Cambio']
        ),
        use_container_width=True
    )
    
    # MÃ©tricas de impacto de la optimizaciÃ³n
    st.subheader("ğŸ¯ Impacto de la OptimizaciÃ³n")
    
    # Calcular mejoras porcentuales
    density_improvement = ((optimized_metrics['density'] - original_metrics['density']) / original_metrics['density']) * 100
    clustering_improvement = ((optimized_metrics['avg_clustering'] - original_metrics['avg_clustering']) / original_metrics['avg_clustering']) * 100
    edges_added = optimized_metrics['num_edges'] - original_metrics['num_edges']
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "ğŸ“Š Mejora en Densidad", 
            f"{density_improvement:+.1f}%",
            help="Incremento porcentual en la densidad de la red"
        )
    
    with col2:
        st.metric(
            "ğŸ•¸ï¸ Mejora en Clustering", 
            f"{clustering_improvement:+.1f}%",
            help="Incremento porcentual en clustering"
        )
    
    with col3:
        st.metric(
            "ğŸ”— Conexiones AÃ±adidas", 
            f"+{edges_added}",
            help="Nuevas conexiones creadas por la optimizaciÃ³n"
        )
    
    with col4:
        # Calcular diversidad de conexiones
        original_connections = set()
        for u, v in G.edges():
            original_connections.add((min(u, v), max(u, v)))
        
        optimized_connections = set()
        for u, v in G_optimized.edges():
            optimized_connections.add((min(u, v), max(u, v)))
        
        new_connections = optimized_connections - original_connections
        diversity_improvement = len(new_connections)
        
        st.metric(
            "ğŸ¯ Nuevas Colaboraciones", 
            diversity_improvement,
            help="NÃºmero de nuevas colaboraciones Ãºnicas"
        )
    
    # AnÃ¡lisis de impacto por desarrollador
    st.subheader("ğŸ‘¥ Impacto por Desarrollador")
    
    developer_impact = []
    for dev in G.nodes():
        original_degree = G.degree(dev, weight='weight')
        optimized_degree = G_optimized.degree(dev, weight='weight')
        degree_change = optimized_degree - original_degree
        
        original_betweenness = original_metrics['betweenness_centrality'][dev]
        optimized_betweenness = optimized_metrics['betweenness_centrality'][dev]
        betweenness_change = optimized_betweenness - original_betweenness
        
        developer_impact.append({
            'Desarrollador': dev,
            'Cambio en Grado': f"{degree_change:+.1f}",
            'Cambio en IntermediaciÃ³n': f"{betweenness_change:+.3f}",
            'Impacto Total': abs(degree_change) + abs(betweenness_change * 10)  # Score compuesto
        })
    
    impact_df = pd.DataFrame(developer_impact)
    impact_df = impact_df.sort_values('Impacto Total', ascending=False)
    
    st.dataframe(
        impact_df.style.background_gradient(subset=['Impacto Total']),
        use_container_width=True
    )
def show_general_overview(df, G, metrics):
    """Mostrar resumen general del anÃ¡lisis"""
    st.markdown('<h2 class="section-header">ğŸ“ˆ Resumen General</h2>', unsafe_allow_html=True)
    
    # MÃ©tricas principales
    col1, col2, col3, col4, col5 = st.columns(5)
    
    with col1:
        st.metric("ğŸ‘¥ Desarrolladores", G.number_of_nodes())
    
    with col2:
        st.metric("ğŸ”— Interacciones", G.number_of_edges())
    
    with col3:
        total_weight = sum([data['weight'] for _, _, data in G.edges(data=True)])
        st.metric("âš–ï¸ Peso Total", total_weight)
    
    with col4:
        density = nx.density(G)
        st.metric("ğŸ“Š Densidad", f"{density:.3f}")
    
    with col5:
        avg_clustering = nx.average_clustering(G.to_undirected())
        st.metric("ğŸ•¸ï¸ Clustering", f"{avg_clustering:.3f}")
    
    st.markdown("---")
    
    # NUEVA SECCIÃ“N: Tabla de datos del dataset
    st.subheader("ğŸ“‹ Vista de Datos del Dataset")
    st.dataframe(df.head(20), use_container_width=True)
    
    # NUEVA SECCIÃ“N: EstadÃ­sticas detalladas
    st.subheader("ğŸ“Š EstadÃ­sticas Detalladas")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Por Desarrollador:**")
        dev_stats = df.groupby('developer_source').agg({
            'weight': 'sum',
            'developer_target': 'count',
            'repo': 'nunique'
        }).rename(columns={
            'weight': 'Peso Total',
            'developer_target': 'Interacciones',
            'repo': 'Repositorios'
        }).head(10)
        st.dataframe(dev_stats)
    
    with col2:
        st.write("**Por Tipo de InteracciÃ³n:**")
        interaction_stats = df.groupby('interaction_type').agg({
            'weight': ['count', 'sum', 'mean']
        }).round(2)
        interaction_stats.columns = ['Cantidad', 'Peso Total', 'Peso Promedio']
        st.dataframe(interaction_stats)
    
    # DistribuciÃ³n de datos
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š DistribuciÃ³n por Tipo de InteracciÃ³n")
        interaction_counts = df['interaction_type'].value_counts()
        
        fig = px.pie(
            values=interaction_counts.values,
            names=interaction_counts.index,
            title="Tipos de InteracciÃ³n en GitHub",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        fig.update_traces(textposition='inside', textinfo='percent+label')
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        st.subheader("ğŸ“ˆ DistribuciÃ³n por Repositorio")
        repo_counts = df['repo'].value_counts().head(10)
        
        fig = px.bar(
            x=repo_counts.values,
            y=repo_counts.index,
            orientation='h',
            title="Top 10 Repositorios por Actividad",
            color=repo_counts.values,
            color_continuous_scale="viridis"
        )
        fig.update_layout(yaxis_title="Repositorio", xaxis_title="NÃºmero de Interacciones")
        st.plotly_chart(fig, use_container_width=True)
    
    # EstadÃ­sticas avanzadas con IA
    st.subheader("ğŸ¤– AnÃ¡lisis Inteligente de Datos")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        # AnÃ¡lisis de diversidad
        unique_pairs = len(df[['developer_source', 'developer_target']].drop_duplicates())
        total_possible = G.number_of_nodes() * (G.number_of_nodes() - 1)
        diversity_score = unique_pairs / max(1, total_possible) * 100
        
        st.metric(
            "ğŸ¯ Diversidad de Colaboraciones", 
            f"{diversity_score:.1f}%",
            help="Porcentaje de colaboraciones Ãºnicas posibles que existen"
        )
    
    with col2:
        # Intensidad promedio
        avg_intensity = df.groupby(['developer_source', 'developer_target'])['weight'].sum().mean()
        st.metric(
            "âš¡ Intensidad Promedio",
            f"{avg_intensity:.1f}",
            help="Peso promedio de colaboraciones entre desarrolladores"
        )
    
    with col3:
        # Factor de reciprocidad
        reciprocity = nx.reciprocity(G)
        st.metric(
            "ğŸ”„ Reciprocidad",
            f"{reciprocity:.3f}",
            help="Grado de colaboraciones bidireccionales"
        )
# Mantener las funciones existentes
def show_ai_community_analysis(G, ai_community_detector, df, method):
    """Mostrar anÃ¡lisis de comunidades con IA"""
    st.markdown('<h2 class="section-header">ğŸ‘¥ AnÃ¡lisis de Comunidades con IA</h2>', unsafe_allow_html=True)
    
    st.markdown(f'<div class="ai-highlight">ğŸ¤– Usando algoritmo: {method.upper()}</div>', unsafe_allow_html=True)
    
    try:
        with st.spinner("ğŸ”„ Detectando comunidades con IA..."):
            communities = ai_community_detector.detect_communities(method=method)
            community_stats = ai_community_detector.get_community_stats()
            quality_metrics = ai_community_detector.get_community_quality_metrics()
        
        # MÃ©tricas principales
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ğŸ˜ï¸ Comunidades", community_stats['num_communities'])
        
        with col2:
            st.metric("ğŸ“Š Modularidad", f"{quality_metrics['modularity']:.3f}")
        
        with col3:
            st.metric("ğŸ“ˆ Cobertura", f"{quality_metrics.get('coverage', 0):.3f}")
        
        with col4:
            st.metric("âš¡ Performance", f"{quality_metrics.get('performance', 0):.3f}")
        
        # VisualizaciÃ³n de comunidades
        st.subheader("ğŸ¨ VisualizaciÃ³n de Comunidades IA")
        community_fig = ai_community_detector.visualize_communities()
        st.plotly_chart(community_fig, use_container_width=True)
        
        # NUEVA SECCIÃ“N: Detalles de cada comunidad
        st.subheader("ğŸ“‹ Detalles por Comunidad")
        
        community_details = {}
        for node, comm_id in communities.items():
            if comm_id not in community_details:
                community_details[comm_id] = []
            community_details[comm_id].append(node)
        
        for comm_id, members in community_details.items():
            with st.expander(f"ğŸ‘¥ Comunidad {comm_id} ({len(members)} miembros)"):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write("**Miembros:**")
                    # Obtener mÃ©tricas si estÃ¡n disponibles
                    try:
                        from network_analyzer import NetworkAnalyzer
                        analyzer = NetworkAnalyzer(G)
                        metrics = analyzer.calculate_all_metrics()
                        
                        for member in members:
                            pagerank_score = metrics.get('pagerank', {}).get(member, 0)
                            st.write(f"â€¢ {member} (PR: {pagerank_score:.3f})")
                    except:
                        for member in members:
                            st.write(f"â€¢ {member}")
                
                with col2:
                    # EstadÃ­sticas de la comunidad
                    comm_interactions = df[
                        (df['developer_source'].isin(members)) | 
                        (df['developer_target'].isin(members))
                    ]
                    
                    st.metric("ğŸ”— Interacciones Totales", len(comm_interactions))
                    st.metric("ğŸ“ Repositorios", comm_interactions['repo'].nunique())
                    
                    if len(comm_interactions) > 0:
                        st.metric("âš–ï¸ Peso Promedio", f"{comm_interactions['weight'].mean():.2f}")
                        
                        # Mostrar repositorios mÃ¡s activos en esta comunidad
                        top_repos = comm_interactions['repo'].value_counts().head(3)
                        st.write("**Top Repositorios:**")
                        for repo, count in top_repos.items():
                            st.write(f"â€¢ {repo}: {count} interacciones")
        
        # OptimizaciÃ³n de comunidades
        st.subheader("ğŸš€ OptimizaciÃ³n de Comunidades")
        
        if st.button("ğŸ¤– Ejecutar OptimizaciÃ³n GenÃ©tica"):
            with st.spinner("ğŸ§¬ Optimizando estructura de comunidades..."):
                optimization_results = ai_community_detector.optimize_community_structure()
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric(
                    "ğŸ“Š Modularidad Original",
                    f"{optimization_results['original_modularity']:.4f}"
                )
            
            with col2:
                if optimization_results['improvement_achieved']:
                    improvement = optimization_results['modularity_improvement']
                    st.metric(
                        "ğŸ“ˆ Mejora Conseguida",
                        f"+{improvement:.4f}",
                        delta=f"{improvement:.4f}"
                    )
                else:
                    st.metric("ğŸ“ˆ Mejora Conseguida", "No significativa")
            
            st.success("âœ… OptimizaciÃ³n completada con algoritmo genÃ©tico")
    
    except Exception as e:
        st.error(f"âŒ Error en anÃ¡lisis de comunidades: {str(e)}")
        st.info("ğŸ’¡ Intenta con un mÃ©todo diferente o verifica las dependencias")
def show_collaboration_patterns(ai_optimizer):
    """Mostrar patrones de colaboraciÃ³n detectados por IA"""
    st.markdown('<h2 class="section-header">ğŸ“Š Patrones Colaborativos con IA</h2>', unsafe_allow_html=True)
    
    with st.spinner("ğŸ”„ Detectando patrones con algoritmos de IA..."):
        patterns = ai_optimizer.detect_collaboration_patterns()
    
    # Patrones temporales
    st.subheader("â° Patrones Temporales")
    
    temporal_patterns = patterns['temporal_patterns']
    
    if 'peak_hours' in temporal_patterns and temporal_patterns['peak_hours']:
        col1, col2 = st.columns(2)
        
        with col1:
            # Horas pico
            hours_df = pd.DataFrame(list(temporal_patterns['peak_hours'].items()), 
                                  columns=['Hora', 'Colaboraciones'])
            
            fig = px.bar(hours_df, x='Hora', y='Colaboraciones', 
                        title="Horas Pico de ColaboraciÃ³n")
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # DÃ­as activos
            if 'active_days' in temporal_patterns:
                days_df = pd.DataFrame(list(temporal_patterns['active_days'].items()), 
                                     columns=['DÃ­a', 'Colaboraciones'])
                
                fig = px.pie(days_df, values='Colaboraciones', names='DÃ­a',
                            title="DistribuciÃ³n por DÃ­a de la Semana")
                st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ğŸ“… No hay datos temporales disponibles para anÃ¡lisis de patrones")
    
    # Patrones por repositorio
    st.subheader("ğŸ“ Patrones por Repositorio")
    
    repo_patterns = patterns['repository_patterns']
    
    if repo_patterns:
        repo_stats_list = []
        for repo, stats in repo_patterns.items():
            repo_stats_list.append({
                'Repositorio': repo,
                'Colaboraciones': stats['total_collaborations'],
                'Desarrolladores': stats['unique_developers'],
                'Peso Promedio': stats['avg_weight'],
                'Densidad': stats['collaboration_density']
            })
        
        repo_stats_df = pd.DataFrame(repo_stats_list)
        
        fig = px.scatter(repo_stats_df, 
                        x='Desarrolladores', 
                        y='Colaboraciones',
                        size='Peso Promedio',
                        color='Densidad',
                        hover_name='Repositorio',
                        title="AnÃ¡lisis de Repositorios - Desarrolladores vs Colaboraciones")
        
        st.plotly_chart(fig, use_container_width=True)
    
    # Patrones de influencia
    st.subheader("ğŸ‘‘ Patrones de Influencia")
    
    influence_patterns = patterns['influence_patterns']
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ† Top Influenciadores (PageRank):**")
        for dev, score in influence_patterns['top_influencers']:
            st.write(f"â€¢ {dev}: {score:.4f}")
    
    with col2:
        st.write("**ğŸŒ‰ Top Constructores de Puentes:**")
        for dev, score in influence_patterns['bridge_builders']:
            st.write(f"â€¢ {dev}: {score:.4f}")

def show_ai_recommendations(G, metrics, ai_optimizer, df):
    """Mostrar recomendaciones generadas por IA"""
    st.markdown('<h2 class="section-header">ğŸ“‹ Recomendaciones Inteligentes</h2>', unsafe_allow_html=True)
    
    st.markdown('<div class="ai-highlight">ğŸ¯ Recomendaciones generadas por algoritmos de Machine Learning para optimizar la colaboraciÃ³n</div>', unsafe_allow_html=True)
    
    # Generar recomendaciones
    with st.spinner("ğŸ”„ Generando recomendaciones con IA..."):
        recommendations = ai_optimizer.recommend_collaborations(top_k=10)
        team_optimization = ai_optimizer.optimize_team_formation(team_size=4, n_teams=3)
    
    # Recomendaciones de colaboraciÃ³n
    st.subheader("ğŸ¤ Nuevas Colaboraciones Recomendadas")
    
    if recommendations:
        rec_df = pd.DataFrame(recommendations)
        display_df = rec_df[['developer_1', 'developer_2', 'composite_score', 'similarity_score', 'reason']]
        display_df.columns = ['Desarrollador 1', 'Desarrollador 2', 'Score IA', 'Similitud', 'RazÃ³n']
        
        st.dataframe(
            display_df.style.background_gradient(subset=['Score IA']).format({
                'Score IA': '{:.3f}',
                'Similitud': '{:.3f}'
            }),
            use_container_width=True
        )
    
    # FormaciÃ³n de equipos
    st.subheader("ğŸ‘¥ Equipos Recomendados")
    
    for team_name, members in team_optimization['balanced_teams'].items():
        with st.expander(f"ğŸ‘¥ {team_name} ({len(members)} miembros)"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**Miembros:**")
                for member in members:
                    pagerank_score = metrics['pagerank'].get(member, 0)
                    st.write(f"â€¢ {member} (PR: {pagerank_score:.3f})")
            
            with col2:
                team_metrics = team_optimization['balanced_metrics']['team_diversity_scores'].get(team_name, {})
                if team_metrics:
                    st.metric("Conexiones Internas", team_metrics.get('internal_connections', 0))
                    st.metric("Fuerza Promedio", f"{team_metrics.get('avg_connection_strength', 0):.2f}")

if __name__ == "__main__":
    main()